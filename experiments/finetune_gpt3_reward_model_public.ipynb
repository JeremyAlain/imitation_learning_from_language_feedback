{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMjk381WnGfvxZvCP3Y1A77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeremyAlain/imitation_learning_from_language_feedback/blob/feature%2Fadd_all_relevant_files/finetune_gpt3_reward_model_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25PMRTjjSR2D",
        "outputId": "72439088-65d2-4ba1-ca23-f9c30363e52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44 kB 1.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147 kB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182 kB 73.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174 kB 64.9 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 173 kB 71.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168 kB 77.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168 kB 64.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166 kB 64.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166 kB 51.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162 kB 41.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 162 kB 29.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 158 kB 68.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 60.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 64.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 45.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 40.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 71.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 49.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157 kB 60.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156 kB 55.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: openai, pathtools\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=07d3512e2e139d868e5f720cd14d0707407f4ce4b318c3d3bed14de90cbd2280\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a9321f57f93a4dfcf69c6c371b618804409f980767b87b88904e02a9aa73062b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built openai pathtools\n",
            "Installing collected packages: smmap, types-pytz, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, pandas-stubs, GitPython, docker-pycreds, wandb, openai\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 openai-0.25.0 pandas-stubs-1.5.2.221213 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 types-pytz-2022.7.0.0 wandb-0.13.7\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 761 kB 4.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386 kB 20.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6 MB 50.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 8.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai wandb\n",
        "!pip install -Uqq ipdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "from google.colab import drive \n",
        "import openai \n",
        "import wandb\n",
        "from openai.wandb_logger import WandbLogger\n",
        "from pathlib import Path\n",
        "from typing import List, Union, Dict, Any\n",
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "import ipdb\n",
        "\n",
        "\n",
        "root_path = \"/content/drive/MyDrive/training_language_models_with_language_feedback_at_scale\"\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "openai.api_key=\"\"\n",
        "%env OPENAI_API_KEY="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZTLBmFEUG80",
        "outputId": "f1a0f518-6f5a-42b8-ed82-08a96d561633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "env: OPENAI_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_dataset_to_openai(dataset_path: str) -> Dict[str, str]: \n",
        "  dataset_path = os.path.join(root_path, dataset_path)\n",
        "  assert Path(dataset_path).exists(), dataset_path\n",
        "  train_object = openai.File.create(\n",
        "      file=open(dataset_path), \n",
        "      purpose=\"fine-tune\"\n",
        "  )\n",
        "  return train_object[\"id\"]"
      ],
      "metadata": {
        "id": "uD0jnxYyVlBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_gpt3_finetuning_job(config: Dict[str, Any], train_dataset_id: str,validation_dataset_id: str, finetuning_summaries: List[str], finetuning_ids: List[str], positive_class: str, suffix: str, use_all_hyperparameters: bool=True) -> None:\n",
        "  if use_all_hyperparameters:   \n",
        "    finetuning_summary = openai.FineTune.create(\n",
        "                          training_file=train_dataset_id, \n",
        "                          validation_file=validation_dataset_id,\n",
        "                          model=\"davinci\",\n",
        "                          learning_rate_multiplier=config[\"learning_rate_multiplier\"],\n",
        "                          prompt_loss_weight=config[\"prompt_loss_weight\"], \n",
        "                          n_epochs=config[\"n_epochs\"], \n",
        "                          batch_size=config[\"batch_size\"], \n",
        "                          compute_classification_metrics=True,\n",
        "                          classification_n_classes=2, \n",
        "                          classification_positive_class=positive_class,\n",
        "                          suffix=suffix)\n",
        "  else: \n",
        "    if \"batch_size\" in config or \"learning_rate_multiplier\" in config: \n",
        "      raise NotImplementedError()\n",
        "    finetuning_summary = openai.FineTune.create(\n",
        "                          training_file=train_dataset_id, \n",
        "                          validation_file=validation_dataset_id,\n",
        "                          model=\"davinci\",\n",
        "                          n_epochs=config[\"n_epochs\"], \n",
        "                          prompt_loss_weight=config[\"prompt_loss_weight\"], \n",
        "                          compute_classification_metrics=True,\n",
        "                          classification_n_classes=2, \n",
        "                          classification_positive_class=positive_class,\n",
        "                          suffix=suffix)\n",
        "  finetuning_summaries.append(finetuning_summary)\n",
        "  finetuning_ids.append(finetuning_summary[\"id\"])\n",
        "  print(\"Initialized job\", finetuning_summary['id'])\n",
        "  print(\"with config\", config)\n",
        "  print(\"\\n\\n\")\n",
        "  return finetuning_summaries, finetuning_ids"
      ],
      "metadata": {
        "id": "wsGlv0cXXTXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kill_all_active_jobs():\n",
        "  for ft in openai.FineTune.list()['data']:\n",
        "    if ft['status'] == 'pending' or ft['status'] == 'running':\n",
        "      print(\"Found\", ft['id'], ft['status'], \"... killing.\")\n",
        "      openai.FineTune.cancel(id=ft['id'])\n",
        "  print(\"No more active jobs.\")"
      ],
      "metadata": {
        "id": "csGFQ8ORakCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_all_active_jobs():\n",
        "  for ft in openai.FineTune.list()['data']:\n",
        "    if ft['status'] == 'pending' or ft['status'] == 'running':\n",
        "      print(\"Found\", ft['id'], ft['status'])\n",
        "  print(\"No more active jobs.\")"
      ],
      "metadata": {
        "id": "-HPdLRKkakHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_job_status_of_job_ids(job_ids: List[str]=None): \n",
        "  for finetuning_id in openai.FineTune.list()[\"data\"]: \n",
        "    if job_ids and finetuning_id['id'] not in job_ids:\n",
        "      continue\n",
        "    print(finetuning_id['id'], finetuning_id['status'])"
      ],
      "metadata": {
        "id": "wHQJm__GQDLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_parameter_sets(sweep_parameters: Dict[str, Any]): \n",
        "  list_of_parameters = []\n",
        "  list_of_values = []\n",
        "  for parameter, value_list in sweep_parameters.items():\n",
        "    list_of_parameters.append(parameter)\n",
        "    list_of_values.append(value_list)\n",
        "\n",
        "  all_combinations_of_values = itertools.product(*list_of_values)\n",
        "\n",
        "  parameter_sets = []\n",
        "  for value_combinations in all_combinations_of_values:\n",
        "    parameterset = {parameter_name: value for parameter_name, value in zip(list_of_parameters, value_combinations)}\n",
        "    parameter_sets.append(parameterset)\n",
        "  return parameter_sets"
      ],
      "metadata": {
        "id": "dNReQ0d6J7eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-3 Reward Model - Comparison"
      ],
      "metadata": {
        "id": "kHhrtWB5VWX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Loss Weight Tuning on 1K Dataset"
      ],
      "metadata": {
        "id": "nSfKBMMlJZsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb off"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgr-uBefLhCl",
        "outputId": "a44dba59-fcb2-4b04-9f49-2979ab87a25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned OFF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_tag = \"reward_model_comparison_sweep\"\n",
        "sweep_parameters = {\n",
        "                    \"prompt_loss_weight\":[0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5], \n",
        "}\n",
        "suffix = \"reward_model_comparison\""
      ],
      "metadata": {
        "id": "reA5fA3kJgs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_sets_for_sweep = build_parameter_sets(sweep_parameters)\n",
        "print(\"Number of configs\", len(parameter_sets_for_sweep))\n",
        "for config in parameter_sets_for_sweep:\n",
        "  print(config)"
      ],
      "metadata": {
        "id": "LJhGhzUqJgvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2a2aa5-b12f-4542-b7d4-619fd9bee523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of configs 7\n",
            "{'prompt_loss_weight': 0, 'suffix': 'reward_model_comparison_sweep'}\n",
            "{'prompt_loss_weight': 0.001, 'suffix': 'reward_model_comparison_sweep'}\n",
            "{'prompt_loss_weight': 0.005, 'suffix': 'reward_model_comparison_sweep'}\n",
            "{'prompt_loss_weight': 0.01, 'suffix': 'reward_model_comparison_sweep'}\n",
            "{'prompt_loss_weight': 0.05, 'suffix': 'reward_model_comparison_sweep'}\n",
            "{'prompt_loss_weight': 0.1, 'suffix': 'reward_model_comparison_sweep'}\n",
            "{'prompt_loss_weight': 0.5, 'suffix': 'reward_model_comparison_sweep'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_comparison_dataset_path = \"summarization_finetuning_datasets/reward_model_comparison_finetuning_dataset_train_1000.jsonl\"\n",
        "train_comparison_dataset_id = upload_dataset_to_openai(train_comparison_dataset_path)\n",
        "dev_comparison_dataset_path = \"summarization_finetuning_datasets/reward_model_comparison_finetuning_dataset_validation_200.jsonl\"\n",
        "development_comparison_dataset_id = upload_dataset_to_openai(dev_comparison_dataset_path)\n",
        "print(\"Train dataset id {}\".format(train_comparison_dataset_id))\n",
        "print(\"Validation dataset id {}\".format(development_comparison_dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JNTXFQwJgyD",
        "outputId": "8e49e13d-dc37-4140-d82c-a831177b1e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset id file-jv1mB4uAktRCps2RFCXPYKFD\n",
            "Validation dataset id file-0TGS9QU0r5K689NOggUkw46U\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = [], []\n",
        "for parameter_set in parameter_sets_for_sweep: \n",
        "  finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = initialize_gpt3_finetuning_job(config=parameter_set, train_dataset_id=train_comparison_dataset_id, validation_dataset_id=development_comparison_dataset_id, finetuning_summaries=finetuning_summaries_hp_tuning, finetuning_ids=finetuning_ids_hp_tuning, positive_class=\" A\", suffix=suffix, use_all_hyperparameters=False)\n",
        "print(finetuning_ids_hp_tuning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuMbYUYZJg0c",
        "outputId": "09a41fd4-6141-41e9-d670-925435450e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized job ft-gKrIAUcfIbNIq4276lbIIZTn\n",
            "with config {'prompt_loss_weight': 0, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-gW5yYQ8CTC42EXCFdikeTnmH\n",
            "with config {'prompt_loss_weight': 0.001, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-QmnVVQ1XzciWD5LDMGH3tiNU\n",
            "with config {'prompt_loss_weight': 0.005, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-KiUIQloVoJotOoop1t770ptl\n",
            "with config {'prompt_loss_weight': 0.01, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-coRZDkwVEw2AIa13qskuKJM5\n",
            "with config {'prompt_loss_weight': 0.05, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-qQ0QUf8ACalGMg9QVEHSqurB\n",
            "with config {'prompt_loss_weight': 0.1, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-we6h6rvw0wOeVthCmio9MyWh\n",
            "with config {'prompt_loss_weight': 0.5, 'suffix': 'reward_model_comparison_sweep'}\n",
            "\n",
            "\n",
            "\n",
            "['ft-gKrIAUcfIbNIq4276lbIIZTn', 'ft-gW5yYQ8CTC42EXCFdikeTnmH', 'ft-QmnVVQ1XzciWD5LDMGH3tiNU', 'ft-KiUIQloVoJotOoop1t770ptl', 'ft-coRZDkwVEw2AIa13qskuKJM5', 'ft-qQ0QUf8ACalGMg9QVEHSqurB', 'ft-we6h6rvw0wOeVthCmio9MyWh']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.get -i \"ft-QmnVVQ1XzciWD5LDMGH3tiNU\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzLhGDBGutNq",
        "outputId": "9982146a-1905-4243-b064-6df4235a4fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1669798212,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1669798212,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-QmnVVQ1XzciWD5LDMGH3tiNU\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669807231,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune costs $53.45\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669807232,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune enqueued. Queue number: 2\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669807232,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669807409,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669807501,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669807617,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune started\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669809110,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669809908,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669810184,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669810423,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune started\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": 2,\n",
            "    \"classification_n_classes\": 2,\n",
            "    \"classification_positive_class\": \" A\",\n",
            "    \"compute_classification_metrics\": true,\n",
            "    \"learning_rate_multiplier\": 0.1,\n",
            "    \"n_epochs\": 4,\n",
            "    \"prompt_loss_weight\": 0.005\n",
            "  },\n",
            "  \"id\": \"ft-QmnVVQ1XzciWD5LDMGH3tiNU\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-rRALD2hkdlmLWNVCKk9PG5Xq\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"running\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 1918584,\n",
            "      \"created_at\": 1669798111,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-jv1mB4uAktRCps2RFCXPYKFD\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1669810423,\n",
            "  \"validation_files\": [\n",
            "    {\n",
            "      \"bytes\": 374975,\n",
            "      \"created_at\": 1669798112,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-0TGS9QU0r5K689NOggUkw46U\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  print(f\"Monitoring {finetuning_id} ...\")\n",
        "  !openai api fine_tunes.follow -i {finetuning_id}\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no1gixOjOuRY",
        "outputId": "ad617718-ef27-4ed7-f2af-0c7a53ba74b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring ft-gKrIAUcfIbNIq4276lbIIZTn ...\n",
            "[2022-11-30 08:50:12] Created fine-tune: ft-gKrIAUcfIbNIq4276lbIIZTn\n",
            "[2022-11-30 08:50:17] Fine-tune costs $53.45\n",
            "[2022-11-30 08:50:18] Fine-tune enqueued. Queue number: 2\n",
            "[2022-11-30 08:52:42] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 08:55:39] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 09:07:07] Fine-tune started\n",
            "[2022-11-30 09:18:42] Completed epoch 1/4\n",
            "[2022-11-30 09:29:14] Completed epoch 2/4\n",
            "[2022-11-30 09:39:42] Completed epoch 3/4\n",
            "[2022-11-30 09:50:07] Completed epoch 4/4\n",
            "[2022-11-30 09:51:19] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-09-51-19\n",
            "[2022-11-30 09:51:21] Uploaded result file: file-HMzhvDEpuu4AG90r1N5MWBMJ\n",
            "[2022-11-30 09:51:21] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-09-51-19 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-gW5yYQ8CTC42EXCFdikeTnmH ...\n",
            "[2022-11-30 08:50:12] Created fine-tune: ft-gW5yYQ8CTC42EXCFdikeTnmH\n",
            "[2022-11-30 09:51:27] Fine-tune costs $53.45\n",
            "[2022-11-30 09:51:27] Fine-tune enqueued. Queue number: 0\n",
            "[2022-11-30 09:51:29] Fine-tune started\n",
            "[2022-11-30 10:03:12] Completed epoch 1/4\n",
            "[2022-11-30 10:13:43] Completed epoch 2/4\n",
            "[2022-11-30 10:24:12] Completed epoch 3/4\n",
            "[2022-11-30 10:34:41] Completed epoch 4/4\n",
            "[2022-11-30 10:35:50] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-10-35-50\n",
            "[2022-11-30 10:35:53] Uploaded result file: file-OotUSx1sMOnwIqeu1qTbkjrW\n",
            "[2022-11-30 10:35:53] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-10-35-50 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-QmnVVQ1XzciWD5LDMGH3tiNU ...\n",
            "[2022-11-30 08:50:12] Created fine-tune: ft-QmnVVQ1XzciWD5LDMGH3tiNU\n",
            "[2022-11-30 11:20:31] Fine-tune costs $53.45\n",
            "[2022-11-30 11:20:32] Fine-tune enqueued. Queue number: 2\n",
            "[2022-11-30 11:20:32] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-30 11:23:29] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 11:25:01] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 11:26:57] Fine-tune started\n",
            "[2022-11-30 11:51:50] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-30 12:05:08] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 12:09:44] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 12:13:43] Fine-tune started\n",
            "[2022-11-30 12:25:46] Completed epoch 1/4\n",
            "[2022-11-30 12:36:21] Completed epoch 2/4\n",
            "[2022-11-30 12:46:58] Completed epoch 3/4\n",
            "[2022-11-30 12:57:32] Completed epoch 4/4\n",
            "[2022-11-30 12:58:35] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-12-58-34\n",
            "[2022-11-30 12:58:36] Uploaded result file: file-AainDMBQWMMWoGL50LJBOEe0\n",
            "[2022-11-30 12:58:36] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-12-58-34 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-KiUIQloVoJotOoop1t770ptl ...\n",
            "[2022-11-30 08:50:12] Created fine-tune: ft-KiUIQloVoJotOoop1t770ptl\n",
            "[2022-11-30 14:12:29] Fine-tune costs $53.45\n",
            "[2022-11-30 14:12:29] Fine-tune enqueued. Queue number: 6\n",
            "[2022-11-30 14:15:31] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-11-30 14:18:09] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-11-30 14:20:38] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-11-30 14:24:44] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-30 14:36:10] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 14:36:11] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 14:40:00] Fine-tune started\n",
            "[2022-11-30 14:51:49] Completed epoch 1/4\n",
            "[2022-11-30 15:02:28] Completed epoch 2/4\n",
            "[2022-11-30 15:13:01] Completed epoch 3/4\n",
            "[2022-11-30 15:23:35] Completed epoch 4/4\n",
            "[2022-11-30 15:24:42] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-15-24-41\n",
            "[2022-11-30 15:24:43] Uploaded result file: file-qTmrqeDMtBad4oLFDZ3zzxVo\n",
            "[2022-11-30 15:24:43] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-15-24-41 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-coRZDkwVEw2AIa13qskuKJM5 ...\n",
            "[2022-11-30 08:50:13] Created fine-tune: ft-coRZDkwVEw2AIa13qskuKJM5\n",
            "[2022-11-30 12:58:37] Fine-tune costs $53.45\n",
            "[2022-11-30 12:58:37] Fine-tune enqueued. Queue number: 1\n",
            "[2022-11-30 12:58:39] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 13:00:46] Fine-tune started\n",
            "[2022-11-30 13:12:35] Completed epoch 1/4\n",
            "[2022-11-30 13:27:57] Fine-tune started\n",
            "[2022-11-30 13:39:39] Completed epoch 1/4\n",
            "[2022-11-30 13:50:08] Completed epoch 2/4\n",
            "[2022-11-30 14:00:38] Completed epoch 3/4\n",
            "[2022-11-30 14:11:11] Completed epoch 4/4\n",
            "[2022-11-30 14:12:19] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-14-12-18\n",
            "[2022-11-30 14:12:20] Uploaded result file: file-MBwulkhOPm3gyFBCgAR756WW\n",
            "[2022-11-30 14:12:20] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-14-12-18 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-qQ0QUf8ACalGMg9QVEHSqurB ...\n",
            "[2022-11-30 08:50:13] Created fine-tune: ft-qQ0QUf8ACalGMg9QVEHSqurB\n",
            "[2022-11-30 10:35:53] Fine-tune costs $53.45\n",
            "[2022-11-30 10:35:54] Fine-tune enqueued. Queue number: 0\n",
            "[2022-11-30 10:35:55] Fine-tune started\n",
            "[2022-11-30 10:47:39] Completed epoch 1/4\n",
            "[2022-11-30 10:58:15] Completed epoch 2/4\n",
            "[2022-11-30 11:08:42] Completed epoch 3/4\n",
            "[2022-11-30 11:19:10] Completed epoch 4/4\n",
            "[2022-11-30 11:20:27] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-11-20-27\n",
            "[2022-11-30 11:20:29] Uploaded result file: file-SdNa9o2pKPxPD9V1NwEk8FRc\n",
            "[2022-11-30 11:20:29] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-11-20-27 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-we6h6rvw0wOeVthCmio9MyWh ...\n",
            "[2022-11-30 08:50:13] Created fine-tune: ft-we6h6rvw0wOeVthCmio9MyWh\n",
            "[2022-11-30 15:24:48] Fine-tune costs $53.45\n",
            "[2022-11-30 15:24:48] Fine-tune enqueued. Queue number: 3\n",
            "[2022-11-30 15:30:10] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-30 15:32:49] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 15:38:34] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 15:40:04] Fine-tune started\n",
            "[2022-11-30 15:58:57] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-30 16:08:34] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 16:11:09] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 16:12:43] Fine-tune started\n",
            "[2022-11-30 16:24:40] Completed epoch 1/4\n",
            "[2022-11-30 16:27:37] Server error. Returning to queue for retry\n",
            "[2022-11-30 16:37:02] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-11-30 16:38:56] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-11-30 16:41:52] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-11-30 16:45:51] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-11-30 16:51:32] Fine-tune started\n",
            "[2022-11-30 17:03:15] Completed epoch 1/4\n",
            "[2022-11-30 17:13:46] Completed epoch 2/4\n",
            "[2022-11-30 17:24:17] Completed epoch 3/4\n",
            "[2022-11-30 17:34:47] Completed epoch 4/4\n",
            "[2022-11-30 17:35:55] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-17-35-55\n",
            "[2022-11-30 17:35:56] Uploaded result file: file-DGhbeWyAK8lCpPB5BJWKu3Vo\n",
            "[2022-11-30 17:35:57] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-11-30-17-35-55 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  WandbLogger.sync(finetuning_id, project=\"training_language_models_with_langauge_feedback\", entity=\"jerry_crea\", tags=[sweep_tag])"
      ],
      "metadata": {
        "id": "u1NKryw3QvHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca34cbe-dd98-4c5d-8a4e-fc2c9eace554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune ft-T54yqskSm2FXzRoctsYXMX9u has the status \"running\" and will not be logged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kill_all_active_jobs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc0UvljQYSMv",
        "outputId": "e6ff4551-115d-4d57-e1c5-6dd50b9de1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found ft-Ef8jeYqwAlhSosvupxWEBqgt pending ... killing.\n",
            "Found ft-sguY0RNxKWPxJ9PZYSqzQPOT pending ... killing.\n",
            "Found ft-nkrbGm1GTRAX7PENTbIZyvtv pending ... killing.\n",
            "Found ft-hhMe1QE3X7azOcCFiHpJ4cgH pending ... killing.\n",
            "Found ft-bbQyi790SVssZH0PWrBmsHCH pending ... killing.\n",
            "Found ft-zRpAcLhYImBaHsNr6A6poGc3 pending ... killing.\n",
            "No more active jobs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_all_active_jobs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhaAqojeYTfT",
        "outputId": "efcedb75-6aaf-417c-8425-448f4cd1a3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No more active jobs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Parameter run \n",
        "\n",
        "- prompt_loss_weight = 0.0\n",
        "- otherwise_default_parameters"
      ],
      "metadata": {
        "id": "JfDyGdr8b2Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_tag = \"reward_model_comparison_final_run\"\n",
        "sweep_parameters = {\n",
        "                    \"prompt_loss_weight\":[0], \n",
        "                    \"n_epochs\": [1]\n",
        "}\n",
        "suffix = \"reward_model_comparison\""
      ],
      "metadata": {
        "id": "YI2ZYmlMcNoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_sets_for_sweep = build_parameter_sets(sweep_parameters)\n",
        "print(\"Number of configs\", len(parameter_sets_for_sweep))\n",
        "for config in parameter_sets_for_sweep:\n",
        "  print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bcaafb-b576-441e-9810-62dacfce1f91",
        "id": "_yPZA4dtcNoR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of configs 1\n",
            "{'prompt_loss_weight': 0, 'n_epochs': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_comparison_dataset_path = \"summarization_finetuning_datasets/reward_model_comparison_finetuning_dataset_train_5000.jsonl\"\n",
        "train_comparison_dataset_id = upload_dataset_to_openai(train_comparison_dataset_path)\n",
        "dev_comparison_dataset_path = \"summarization_finetuning_datasets/reward_model_comparison_finetuning_dataset_validation_200.jsonl\"\n",
        "development_comparison_dataset_id = upload_dataset_to_openai(dev_comparison_dataset_path)\n",
        "print(\"Train dataset id {}\".format(train_comparison_dataset_id))\n",
        "print(\"Validation dataset id {}\".format(development_comparison_dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb05823-e317-4b08-81a5-9351edc73326",
        "id": "N-Gvn2XMcNoS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset id file-2NN9jwFW5MEtWNnQap7HFMhM\n",
            "Validation dataset id file-SDwGhLzwv5IaztMJuFjm8Gk9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = [], []\n",
        "for parameter_set in parameter_sets_for_sweep: \n",
        "  finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = initialize_gpt3_finetuning_job(config=parameter_set, train_dataset_id=train_comparison_dataset_id, validation_dataset_id=development_comparison_dataset_id, finetuning_summaries=finetuning_summaries_hp_tuning, finetuning_ids=finetuning_ids_hp_tuning, positive_class=\" A\", suffix=suffix, use_all_hyperparameters=False)\n",
        "print(finetuning_ids_hp_tuning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e207039-a856-4157-b23a-23e7f68484ff",
        "id": "iSmb5wGMcNoS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized job ft-JLH3Tzcbwc5I40l3VtSSf2i2\n",
            "with config {'prompt_loss_weight': 0, 'n_epochs': 1}\n",
            "\n",
            "\n",
            "\n",
            "['ft-JLH3Tzcbwc5I40l3VtSSf2i2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.get -i \"ft-JLH3Tzcbwc5I40l3VtSSf2i2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145d5427-6b05-45b6-c687-8feece67f427",
        "id": "suT66W-OcNoS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1670055024,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1670055024,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-JLH3Tzcbwc5I40l3VtSSf2i2\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670055046,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune costs $64.41\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670055047,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune enqueued. Queue number: 0\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670055050,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune started\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670056678,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Completed epoch 1/1\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670056740,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-12-03-08-39-00\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670056741,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Uploaded result file: file-SzdmrKBNekEFHmzn4VOIgn7L\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1670056741,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune succeeded\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": \"davinci:ft-academicsnyuperez:reward-model-comparison-2022-12-03-08-39-00\",\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": 8,\n",
            "    \"classification_n_classes\": 2,\n",
            "    \"classification_positive_class\": \" A\",\n",
            "    \"compute_classification_metrics\": true,\n",
            "    \"learning_rate_multiplier\": 0.1,\n",
            "    \"n_epochs\": 1,\n",
            "    \"prompt_loss_weight\": 0.0\n",
            "  },\n",
            "  \"id\": \"ft-JLH3Tzcbwc5I40l3VtSSf2i2\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-rRALD2hkdlmLWNVCKk9PG5Xq\",\n",
            "  \"result_files\": [\n",
            "    {\n",
            "      \"bytes\": 38783,\n",
            "      \"created_at\": 1670056741,\n",
            "      \"filename\": \"compiled_results.csv\",\n",
            "      \"id\": \"file-SzdmrKBNekEFHmzn4VOIgn7L\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 9261058,\n",
            "      \"created_at\": 1670054919,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-2NN9jwFW5MEtWNnQap7HFMhM\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1670056742,\n",
            "  \"validation_files\": [\n",
            "    {\n",
            "      \"bytes\": 374975,\n",
            "      \"created_at\": 1670054921,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-SDwGhLzwv5IaztMJuFjm8Gk9\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_ids_hp_tuning = ['ft-JLH3Tzcbwc5I40l3VtSSf2i2']\n",
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  print(f\"Monitoring {finetuning_id} ...\")\n",
        "  !openai api fine_tunes.follow -i {finetuning_id}\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKGbnJ6KGq9b",
        "outputId": "c37c21bd-320a-48f8-df33-6ad697ada8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring ft-JLH3Tzcbwc5I40l3VtSSf2i2 ...\n",
            "[2022-12-03 08:10:24] Created fine-tune: ft-JLH3Tzcbwc5I40l3VtSSf2i2\n",
            "[2022-12-03 08:10:46] Fine-tune costs $64.41\n",
            "[2022-12-03 08:10:47] Fine-tune enqueued. Queue number: 0\n",
            "[2022-12-03 08:10:50] Fine-tune started\n",
            "[2022-12-03 08:37:58] Completed epoch 1/1\n",
            "[2022-12-03 08:39:00] Uploaded model: davinci:ft-academicsnyuperez:reward-model-comparison-2022-12-03-08-39-00\n",
            "[2022-12-03 08:39:01] Uploaded result file: file-SzdmrKBNekEFHmzn4VOIgn7L\n",
            "[2022-12-03 08:39:01] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-comparison-2022-12-03-08-39-00 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_ids_hp_tuning = ['ft-JLH3Tzcbwc5I40l3VtSSf2i2']\n",
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  WandbLogger.sync(finetuning_id, project=\"training_language_models_with_langauge_feedback\", entity=\"jerry_crea\", tags=[sweep_tag])"
      ],
      "metadata": {
        "id": "RcNIkrCycNoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reward Model Classification"
      ],
      "metadata": {
        "id": "j4FBDEGgoGWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Loss Weight Tuning on 1K Dataset"
      ],
      "metadata": {
        "id": "5nXfLMSwGUVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_tag = \"reward_model_classification_sweep\"\n",
        "sweep_parameters = {\n",
        "                    \"prompt_loss_weight\":[0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5], \n",
        "}\n",
        "suffix = \"reward_model_classification\""
      ],
      "metadata": {
        "id": "sfKZLtGLGVbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_sets_for_sweep = build_parameter_sets(sweep_parameters)\n",
        "print(\"Number of configs\", len(parameter_sets_for_sweep))\n",
        "for config in parameter_sets_for_sweep:\n",
        "  print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37cb2d23-3048-42ef-ba48-ba4c1c0bbde9",
        "id": "34RhakPmGVbH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of configs 7\n",
            "{'prompt_loss_weight': 0}\n",
            "{'prompt_loss_weight': 0.001}\n",
            "{'prompt_loss_weight': 0.005}\n",
            "{'prompt_loss_weight': 0.01}\n",
            "{'prompt_loss_weight': 0.05}\n",
            "{'prompt_loss_weight': 0.1}\n",
            "{'prompt_loss_weight': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_classification_dataset_path = \"summarization_finetuning_datasets/reward_model_classification_finetuning_dataset_train_1000.jsonl\"\n",
        "train_classification_dataset_id = upload_dataset_to_openai(train_classification_dataset_path)\n",
        "dev_classification_dataset_path = \"summarization_finetuning_datasets/reward_model_classification_finetuning_dataset_validation_400.jsonl\"\n",
        "development_classification_dataset_id = upload_dataset_to_openai(dev_classification_dataset_path)\n",
        "print(\"Train dataset id {}\".format(train_classification_dataset_id))\n",
        "print(\"Validation dataset id {}\".format(development_classification_dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8a370e-4bcb-4725-f288-9c0111acbe36",
        "id": "_iR_wg7JGVbI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset id file-1BwTeelH9kMt2SUnrwESPz6d\n",
            "Validation dataset id file-0DbupaEsn1Pt9JQDODwouOde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = [], []\n",
        "for parameter_set in parameter_sets_for_sweep: \n",
        "  finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = initialize_gpt3_finetuning_job(config=parameter_set, train_dataset_id=train_classification_dataset_id, validation_dataset_id=development_classification_dataset_id, finetuning_summaries=finetuning_summaries_hp_tuning, finetuning_ids=finetuning_ids_hp_tuning, positive_class=\" Yes\", suffix=suffix, use_all_hyperparameters=False)\n",
        "print(finetuning_ids_hp_tuning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269ce449-c1c4-4031-f62a-62544a02cb9f",
        "id": "ClE-soXXGVbI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized job ft-gA3vJ1BjYlYc6h0JyIhxLEO5\n",
            "with config {'prompt_loss_weight': 0}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-u9JiZFstyp5LuqvhkLaKgHHF\n",
            "with config {'prompt_loss_weight': 0.001}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-5antcrreE5U0cZbUDtvKntf1\n",
            "with config {'prompt_loss_weight': 0.005}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-SIP7jF1EE1S6EO8H13PS7PCs\n",
            "with config {'prompt_loss_weight': 0.01}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-AgFFLHBxNPjxFxUdj9FloaK7\n",
            "with config {'prompt_loss_weight': 0.05}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-KL2DlrPjFYwJ517NoIJOz9G3\n",
            "with config {'prompt_loss_weight': 0.1}\n",
            "\n",
            "\n",
            "\n",
            "Initialized job ft-ZdWDUbAnwZ4JDw8fwJRWjV4E\n",
            "with config {'prompt_loss_weight': 0.5}\n",
            "\n",
            "\n",
            "\n",
            "['ft-gA3vJ1BjYlYc6h0JyIhxLEO5', 'ft-u9JiZFstyp5LuqvhkLaKgHHF', 'ft-5antcrreE5U0cZbUDtvKntf1', 'ft-SIP7jF1EE1S6EO8H13PS7PCs', 'ft-AgFFLHBxNPjxFxUdj9FloaK7', 'ft-KL2DlrPjFYwJ517NoIJOz9G3', 'ft-ZdWDUbAnwZ4JDw8fwJRWjV4E']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.get -i \"ft-KL2DlrPjFYwJ517NoIJOz9G3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916b95b9-bc92-46a2-ba94-a6d2ec5eeae4",
        "id": "H9hzy7WTGVbI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1669893198,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1669893198,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-KL2DlrPjFYwJ517NoIJOz9G3\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669962750,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune costs $99.60\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669962750,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune enqueued. Queue number: 22\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669964332,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 21\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669964654,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 20\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669964848,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 19\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669966901,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 18\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669967029,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 17\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669967400,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 16\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669967659,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 15\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669968001,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 14\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669968061,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 13\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669968188,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 12\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669968281,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 11\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669968530,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 10\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669971014,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 9\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669971016,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 8\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669971017,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 7\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669971347,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 6\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669972359,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 5\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669972621,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 4\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669972636,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 3\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669972799,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669972808,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669972998,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669973070,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune started\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": 4,\n",
            "    \"classification_n_classes\": 2,\n",
            "    \"classification_positive_class\": \" Yes\",\n",
            "    \"compute_classification_metrics\": true,\n",
            "    \"learning_rate_multiplier\": 0.1,\n",
            "    \"n_epochs\": 4,\n",
            "    \"prompt_loss_weight\": 0.1\n",
            "  },\n",
            "  \"id\": \"ft-KL2DlrPjFYwJ517NoIJOz9G3\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-rRALD2hkdlmLWNVCKk9PG5Xq\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"running\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 3573797,\n",
            "      \"created_at\": 1669893190,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-1BwTeelH9kMt2SUnrwESPz6d\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1669973070,\n",
            "  \"validation_files\": [\n",
            "    {\n",
            "      \"bytes\": 698807,\n",
            "      \"created_at\": 1669893192,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-0DbupaEsn1Pt9JQDODwouOde\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_ids_hp_tuning = ['ft-gA3vJ1BjYlYc6h0JyIhxLEO5', 'ft-u9JiZFstyp5LuqvhkLaKgHHF', 'ft-5antcrreE5U0cZbUDtvKntf1', 'ft-SIP7jF1EE1S6EO8H13PS7PCs', 'ft-AgFFLHBxNPjxFxUdj9FloaK7', 'ft-KL2DlrPjFYwJ517NoIJOz9G3', 'ft-ZdWDUbAnwZ4JDw8fwJRWjV4E']\n",
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  print(f\"Monitoring {finetuning_id} ...\")\n",
        "  !openai api fine_tunes.follow -i {finetuning_id}\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15101587-456f-495b-f429-56cab99db491",
        "id": "mx9ZfEGCGVbI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring ft-gA3vJ1BjYlYc6h0JyIhxLEO5 ...\n",
            "[2022-12-01 11:13:16] Created fine-tune: ft-gA3vJ1BjYlYc6h0JyIhxLEO5\n",
            "[2022-12-01 11:13:27] Fine-tune costs $99.60\n",
            "[2022-12-01 11:13:28] Fine-tune enqueued. Queue number: 20\n",
            "[2022-12-01 11:13:59] Fine-tune is in the queue. Queue number: 19\n",
            "[2022-12-01 11:15:12] Fine-tune is in the queue. Queue number: 18\n",
            "[2022-12-01 11:17:39] Fine-tune is in the queue. Queue number: 17\n",
            "[2022-12-01 11:22:08] Fine-tune is in the queue. Queue number: 16\n",
            "[2022-12-01 11:30:19] Fine-tune is in the queue. Queue number: 15\n",
            "[2022-12-01 11:32:16] Fine-tune is in the queue. Queue number: 14\n",
            "[2022-12-01 11:35:35] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-01 11:36:15] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-01 11:43:28] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-01 11:44:18] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-01 11:45:44] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-01 11:48:00] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-01 11:50:26] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-01 12:01:20] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-01 12:25:03] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-01 12:25:04] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-01 12:32:06] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-01 12:34:24] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-01 12:42:16] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-01 12:50:08] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-01 12:50:09] Fine-tune started\n",
            "[2022-12-01 13:06:00] Completed epoch 1/4\n",
            "[2022-12-01 13:20:50] Completed epoch 2/4\n",
            "[2022-12-01 13:35:48] Completed epoch 3/4\n",
            "[2022-12-01 13:50:41] Completed epoch 4/4\n",
            "[2022-12-01 13:53:11] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-01-13-53-11\n",
            "[2022-12-01 13:53:13] Uploaded result file: file-8tTJrItJhD9lnvFr6BCNmZjc\n",
            "[2022-12-01 13:53:13] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-01-13-53-11 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-u9JiZFstyp5LuqvhkLaKgHHF ...\n",
            "[2022-12-01 11:13:17] Created fine-tune: ft-u9JiZFstyp5LuqvhkLaKgHHF\n",
            "[2022-12-01 13:53:14] Fine-tune costs $99.60\n",
            "[2022-12-01 13:53:15] Fine-tune enqueued. Queue number: 19\n",
            "[2022-12-01 13:53:16] Fine-tune is in the queue. Queue number: 18\n",
            "[2022-12-01 13:59:17] Fine-tune is in the queue. Queue number: 17\n",
            "[2022-12-01 14:00:43] Fine-tune is in the queue. Queue number: 16\n",
            "[2022-12-01 14:01:24] Fine-tune is in the queue. Queue number: 15\n",
            "[2022-12-01 14:04:12] Fine-tune is in the queue. Queue number: 14\n",
            "[2022-12-01 14:06:42] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-01 14:08:59] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-01 14:16:01] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-01 14:22:12] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-01 14:24:28] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-01 14:27:25] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-01 14:32:55] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-01 14:32:56] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-01 14:35:13] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-01 14:37:50] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-01 14:37:51] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-01 14:37:51] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-01 14:39:31] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-01 14:39:59] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-01 14:41:48] Fine-tune started\n",
            "[2022-12-01 14:57:51] Completed epoch 1/4\n",
            "[2022-12-01 15:12:52] Completed epoch 2/4\n",
            "[2022-12-01 15:27:58] Completed epoch 3/4\n",
            "[2022-12-01 15:42:50] Completed epoch 4/4\n",
            "[2022-12-01 15:44:08] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-01-15-44-08\n",
            "[2022-12-01 15:44:09] Uploaded result file: file-QH25ESDA8e581VKrdaO7hSJv\n",
            "[2022-12-01 15:44:09] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-01-15-44-08 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-5antcrreE5U0cZbUDtvKntf1 ...\n",
            "[2022-12-01 11:13:17] Created fine-tune: ft-5antcrreE5U0cZbUDtvKntf1\n",
            "[2022-12-01 15:44:20] Fine-tune costs $99.60\n",
            "[2022-12-01 15:44:21] Fine-tune enqueued. Queue number: 19\n",
            "[2022-12-01 15:50:34] Fine-tune is in the queue. Queue number: 18\n",
            "[2022-12-01 15:54:36] Fine-tune is in the queue. Queue number: 17\n",
            "[2022-12-01 15:59:26] Fine-tune is in the queue. Queue number: 16\n",
            "[2022-12-01 16:01:32] Fine-tune is in the queue. Queue number: 15\n",
            "[2022-12-01 16:03:50] Fine-tune is in the queue. Queue number: 14\n",
            "[2022-12-01 16:49:47] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-01 16:58:12] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-01 17:04:13] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-01 17:06:30] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-01 17:06:31] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-01 17:08:38] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-01 17:11:26] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-01 17:25:14] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-01 17:27:31] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-01 17:37:35] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-01 17:48:32] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-01 18:34:23] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-01 18:51:03] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-01 18:57:45] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-01 19:07:20] Fine-tune started\n",
            "[2022-12-01 19:23:41] Completed epoch 1/4\n",
            "[2022-12-01 19:38:37] Completed epoch 2/4\n",
            "[2022-12-01 19:53:21] Completed epoch 3/4\n",
            "[2022-12-01 20:08:13] Completed epoch 4/4\n",
            "[2022-12-01 20:09:29] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-01-20-09-29\n",
            "[2022-12-01 20:09:31] Uploaded result file: file-su94AsLbKAHyL38SlkeVZTRX\n",
            "[2022-12-01 20:09:31] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-01-20-09-29 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-SIP7jF1EE1S6EO8H13PS7PCs ...\n",
            "[2022-12-01 11:13:17] Created fine-tune: ft-SIP7jF1EE1S6EO8H13PS7PCs\n",
            "[2022-12-01 20:09:40] Fine-tune costs $99.60\n",
            "[2022-12-01 20:09:40] Fine-tune enqueued. Queue number: 26\n",
            "[2022-12-01 20:11:44] Fine-tune is in the queue. Queue number: 25\n",
            "[2022-12-01 20:14:21] Fine-tune is in the queue. Queue number: 24\n",
            "[2022-12-01 20:26:08] Fine-tune is in the queue. Queue number: 23\n",
            "[2022-12-01 20:28:25] Fine-tune is in the queue. Queue number: 22\n",
            "[2022-12-01 20:30:31] Fine-tune is in the queue. Queue number: 21\n",
            "[2022-12-01 20:40:45] Fine-tune is in the queue. Queue number: 20\n",
            "[2022-12-01 20:44:13] Fine-tune is in the queue. Queue number: 19\n",
            "[2022-12-01 21:30:52] Fine-tune is in the queue. Queue number: 18\n",
            "[2022-12-01 21:39:59] Fine-tune is in the queue. Queue number: 17\n",
            "[2022-12-01 21:45:26] Fine-tune is in the queue. Queue number: 16\n",
            "[2022-12-01 21:48:35] Fine-tune is in the queue. Queue number: 15\n",
            "[2022-12-01 21:49:02] Fine-tune is in the queue. Queue number: 14\n",
            "[2022-12-01 21:49:04] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-01 21:50:42] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-01 21:53:03] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-01 21:54:10] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-01 22:11:02] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-01 22:13:19] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-01 22:36:06] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-01 22:38:23] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-01 22:48:07] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-01 22:53:59] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-01 22:57:58] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-01 23:03:29] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-01 23:09:10] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-01 23:11:28] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-01 23:24:39] Fine-tune started\n",
            "[2022-12-01 23:41:51] Completed epoch 1/4\n",
            "[2022-12-01 23:56:52] Completed epoch 2/4\n",
            "[2022-12-02 00:11:55] Completed epoch 3/4\n",
            "[2022-12-02 00:27:02] Completed epoch 4/4\n",
            "[2022-12-02 00:29:01] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-00-29-00\n",
            "[2022-12-02 00:29:02] Uploaded result file: file-Q8oIelsgqqeTlqNNHrhHppbJ\n",
            "[2022-12-02 00:29:02] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-00-29-00 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-AgFFLHBxNPjxFxUdj9FloaK7 ...\n",
            "[2022-12-01 11:13:17] Created fine-tune: ft-AgFFLHBxNPjxFxUdj9FloaK7\n",
            "[2022-12-02 00:29:03] Fine-tune costs $99.60\n",
            "[2022-12-02 00:29:04] Fine-tune enqueued. Queue number: 28\n",
            "[2022-12-02 00:29:06] Fine-tune is in the queue. Queue number: 27\n",
            "[2022-12-02 00:33:05] Fine-tune is in the queue. Queue number: 26\n",
            "[2022-12-02 00:34:25] Fine-tune is in the queue. Queue number: 25\n",
            "[2022-12-02 00:36:43] Fine-tune is in the queue. Queue number: 24\n",
            "[2022-12-02 00:39:28] Fine-tune is in the queue. Queue number: 23\n",
            "[2022-12-02 00:55:53] Fine-tune is in the queue. Queue number: 22\n",
            "[2022-12-02 01:05:26] Fine-tune is in the queue. Queue number: 21\n",
            "[2022-12-02 01:08:24] Fine-tune is in the queue. Queue number: 20\n",
            "[2022-12-02 01:11:02] Fine-tune is in the queue. Queue number: 19\n",
            "[2022-12-02 01:13:11] Fine-tune is in the queue. Queue number: 18\n",
            "[2022-12-02 01:18:43] Fine-tune is in the queue. Queue number: 17\n",
            "[2022-12-02 01:31:03] Fine-tune is in the queue. Queue number: 16\n",
            "[2022-12-02 01:39:57] Fine-tune is in the queue. Queue number: 15\n",
            "[2022-12-02 01:44:15] Fine-tune is in the queue. Queue number: 14\n",
            "[2022-12-02 01:47:22] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-02 01:54:22] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-02 01:54:44] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-02 02:04:51] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-02 03:12:14] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-02 03:16:43] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-02 03:22:14] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-02 03:24:21] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-02 03:29:32] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-02 04:33:50] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-02 04:33:51] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-02 04:39:32] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-02 05:22:46] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-02 05:28:27] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-02 05:30:35] Fine-tune started\n",
            "[2022-12-02 05:46:27] Completed epoch 1/4\n",
            "[2022-12-02 06:01:17] Completed epoch 2/4\n",
            "[2022-12-02 06:16:07] Completed epoch 3/4\n",
            "[2022-12-02 06:30:59] Completed epoch 4/4\n",
            "[2022-12-02 06:32:15] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-06-32-15\n",
            "[2022-12-02 06:32:17] Uploaded result file: file-QORjV5Il4YeOgfRmHryn4hF6\n",
            "[2022-12-02 06:32:17] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-06-32-15 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-KL2DlrPjFYwJ517NoIJOz9G3 ...\n",
            "[2022-12-01 11:13:18] Created fine-tune: ft-KL2DlrPjFYwJ517NoIJOz9G3\n",
            "[2022-12-02 06:32:30] Fine-tune costs $99.60\n",
            "[2022-12-02 06:32:30] Fine-tune enqueued. Queue number: 22\n",
            "[2022-12-02 06:58:52] Fine-tune is in the queue. Queue number: 21\n",
            "[2022-12-02 07:04:14] Fine-tune is in the queue. Queue number: 20\n",
            "[2022-12-02 07:07:28] Fine-tune is in the queue. Queue number: 19\n",
            "[2022-12-02 07:41:41] Fine-tune is in the queue. Queue number: 18\n",
            "[2022-12-02 07:43:49] Fine-tune is in the queue. Queue number: 17\n",
            "[2022-12-02 07:50:00] Fine-tune is in the queue. Queue number: 16\n",
            "[2022-12-02 07:54:19] Fine-tune is in the queue. Queue number: 15\n",
            "[2022-12-02 08:00:01] Fine-tune is in the queue. Queue number: 14\n",
            "[2022-12-02 08:01:01] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-02 08:03:08] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-02 08:04:41] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-02 08:08:50] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-02 08:50:14] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-02 08:50:16] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-02 08:50:17] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-02 08:55:47] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-02 09:12:39] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-02 09:17:01] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-02 09:17:16] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-02 09:19:59] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-02 09:20:08] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-02 09:23:18] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-02 09:24:30] Fine-tune started\n",
            "[2022-12-02 09:40:21] Completed epoch 1/4\n",
            "[2022-12-02 09:55:16] Completed epoch 2/4\n",
            "[2022-12-02 10:10:21] Completed epoch 3/4\n",
            "[2022-12-02 10:25:24] Completed epoch 4/4\n",
            "[2022-12-02 10:26:44] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-10-26-44\n",
            "[2022-12-02 10:26:46] Uploaded result file: file-OmPNzZrPge5VpskgYuDLExur\n",
            "[2022-12-02 10:26:46] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-10-26-44 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n",
            "Monitoring ft-ZdWDUbAnwZ4JDw8fwJRWjV4E ...\n",
            "[2022-12-01 11:13:18] Created fine-tune: ft-ZdWDUbAnwZ4JDw8fwJRWjV4E\n",
            "[2022-12-02 10:26:49] Fine-tune costs $99.60\n",
            "[2022-12-02 10:26:49] Fine-tune enqueued. Queue number: 14\n",
            "[2022-12-02 10:28:50] Fine-tune is in the queue. Queue number: 13\n",
            "[2022-12-02 10:29:58] Fine-tune is in the queue. Queue number: 12\n",
            "[2022-12-02 10:31:28] Fine-tune is in the queue. Queue number: 11\n",
            "[2022-12-02 10:32:17] Fine-tune is in the queue. Queue number: 10\n",
            "[2022-12-02 10:34:34] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-02 10:37:22] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-02 10:43:23] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-02 10:43:24] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-02 10:43:25] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-02 10:44:59] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-02 10:47:18] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-02 10:52:27] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-02 11:19:18] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-02 11:23:58] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-02 11:26:19] Fine-tune started\n",
            "[2022-12-02 11:41:59] Completed epoch 1/4\n",
            "[2022-12-02 11:56:54] Completed epoch 2/4\n",
            "[2022-12-02 12:11:41] Completed epoch 3/4\n",
            "[2022-12-02 12:26:33] Completed epoch 4/4\n",
            "[2022-12-02 12:27:58] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-12-27-58\n",
            "[2022-12-02 12:28:00] Uploaded result file: file-4UqatlGuRBbHt3ZeelIYWTWn\n",
            "[2022-12-02 12:28:00] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-12-27-58 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  WandbLogger.sync(finetuning_id, project=\"training_language_models_with_langauge_feedback\", entity=\"jerry_crea\", tags=[sweep_tag])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ec1d078-e5c0-4217-f5d7-7a15609cc201",
        "id": "XFhw2T49GVbI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune ft-gA3vJ1BjYlYc6h0JyIhxLEO5 has already been logged successfully at https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-gA3vJ1BjYlYc6h0JyIhxLEO5\n",
            "Use \"--force\" in the CLI or \"force=True\" in python if you want to overwrite previous run\n",
            "Fine-tune ft-u9JiZFstyp5LuqvhkLaKgHHF has already been logged successfully at https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-u9JiZFstyp5LuqvhkLaKgHHF\n",
            "Use \"--force\" in the CLI or \"force=True\" in python if you want to overwrite previous run\n",
            "Fine-tune ft-5antcrreE5U0cZbUDtvKntf1 has already been logged successfully at https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-5antcrreE5U0cZbUDtvKntf1\n",
            "Use \"--force\" in the CLI or \"force=True\" in python if you want to overwrite previous run\n",
            "Fine-tune ft-SIP7jF1EE1S6EO8H13PS7PCs has already been logged successfully at https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-SIP7jF1EE1S6EO8H13PS7PCs\n",
            "Use \"--force\" in the CLI or \"force=True\" in python if you want to overwrite previous run\n",
            "Fine-tune ft-AgFFLHBxNPjxFxUdj9FloaK7 has already been logged successfully at https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-AgFFLHBxNPjxFxUdj9FloaK7\n",
            "Use \"--force\" in the CLI or \"force=True\" in python if you want to overwrite previous run\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221202_130442-ft-KL2DlrPjFYwJ517NoIJOz9G3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-KL2DlrPjFYwJ517NoIJOz9G3\" target=\"_blank\">ft-KL2DlrPjFYwJ517NoIJOz9G3</a></strong> to <a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>classification/accuracy</td><td>â–…â–â–‡â–ˆ</td></tr><tr><td>classification/auprc</td><td>â–â–„â–ƒâ–ˆ</td></tr><tr><td>classification/auroc</td><td>â–â–„â–„â–ˆ</td></tr><tr><td>classification/f1.0</td><td>â–ˆâ–‡â–â–„</td></tr><tr><td>classification/precision</td><td>â–ƒâ–â–ˆâ–ˆ</td></tr><tr><td>classification/recall</td><td>â–‡â–ˆâ–â–‚</td></tr><tr><td>elapsed_examples</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>elapsed_tokens</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>training_loss</td><td>â–ˆâ–‡â–…â–†â–‡â–†â–„â–†â–‡â–‡â–…â–†â–‡â–…â–‚â–…â–ƒâ–„â–†â–„â–ƒâ–‚â–„â–‚â–ƒâ–„â–‚â–‚â–„â–…â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒ</td></tr><tr><td>training_sequence_accuracy</td><td>â–â–ƒâ–â–ƒâ–â–†â–â–ƒâ–ƒâ–†â–†â–ƒâ–â–ƒâ–ˆâ–ˆâ–â–†â–â–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–ˆâ–ˆâ–†â–â–â–â–â–ƒâ–â–ƒ</td></tr><tr><td>training_token_accuracy</td><td>â–â–ƒâ–â–ƒâ–â–†â–â–ƒâ–ƒâ–†â–†â–ƒâ–â–ƒâ–ˆâ–ˆâ–â–†â–â–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–ˆâ–ˆâ–†â–â–â–â–â–ƒâ–â–ƒ</td></tr><tr><td>validation_loss</td><td>â–…â–â–ƒâ–…â–ƒâ–‡â–ƒâ–…â–ƒâ–†â–†â–†â–ƒâ–ƒâ–…â–ƒâ–‚â–†â–ƒâ–…â–„â–„â–ƒâ–ƒâ–‚â–„â–ˆâ–‚â–„â–‡â–†â–†â–…â–…â–†â–…â–†â–ƒâ–„â–‡</td></tr><tr><td>validation_sequence_accuracy</td><td>â–ˆâ–…â–†â–ƒâ–ƒâ–†â–†â–…â–â–…â–…â–ƒâ–†â–ƒâ–â–ˆâ–†â–…â–ƒâ–†â–†â–†â–…â–…â–ƒâ–†â–ƒâ–…â–…â–†â–†â–…â–†â–†â–ƒâ–ƒâ–†â–†â–†â–…</td></tr><tr><td>validation_token_accuracy</td><td>â–ˆâ–…â–†â–ƒâ–ƒâ–†â–†â–…â–â–…â–…â–ƒâ–†â–ƒâ–â–ˆâ–†â–…â–ƒâ–†â–†â–†â–…â–…â–ƒâ–†â–ƒâ–…â–…â–†â–†â–…â–†â–†â–ƒâ–ƒâ–†â–†â–†â–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification/accuracy</td><td>0.5775</td></tr><tr><td>classification/auprc</td><td>0.60085</td></tr><tr><td>classification/auroc</td><td>0.6172</td></tr><tr><td>classification/f1.0</td><td>0.62528</td></tr><tr><td>classification/precision</td><td>0.56175</td></tr><tr><td>classification/recall</td><td>0.705</td></tr><tr><td>elapsed_examples</td><td>8004.0</td></tr><tr><td>elapsed_tokens</td><td>4094148.0</td></tr><tr><td>fine_tuned_model</td><td>davinci:ft-academics...</td></tr><tr><td>status</td><td>succeeded</td></tr><tr><td>training_loss</td><td>0.12502</td></tr><tr><td>training_sequence_accuracy</td><td>0.75</td></tr><tr><td>training_token_accuracy</td><td>0.75</td></tr><tr><td>validation_loss</td><td>0.18523</td></tr><tr><td>validation_sequence_accuracy</td><td>0.25</td></tr><tr><td>validation_token_accuracy</td><td>0.25</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">ft-KL2DlrPjFYwJ517NoIJOz9G3</strong>: <a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-KL2DlrPjFYwJ517NoIJOz9G3\" target=\"_blank\">https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-KL2DlrPjFYwJ517NoIJOz9G3</a><br/>Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221202_130442-ft-KL2DlrPjFYwJ517NoIJOz9G3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221202_130454-ft-ZdWDUbAnwZ4JDw8fwJRWjV4E</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-ZdWDUbAnwZ4JDw8fwJRWjV4E\" target=\"_blank\">ft-ZdWDUbAnwZ4JDw8fwJRWjV4E</a></strong> to <a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>classification/accuracy</td><td>â–‚â–â–ˆâ–‡</td></tr><tr><td>classification/auprc</td><td>â–ƒâ–â–ˆâ–„</td></tr><tr><td>classification/auroc</td><td>â–ƒâ–â–ˆâ–‡</td></tr><tr><td>classification/f1.0</td><td>â–ˆâ–ˆâ–‚â–</td></tr><tr><td>classification/precision</td><td>â–‚â–â–ˆâ–‡</td></tr><tr><td>classification/recall</td><td>â–ˆâ–ˆâ–â–</td></tr><tr><td>elapsed_examples</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>elapsed_tokens</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>training_loss</td><td>â–ˆâ–ˆâ–†â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–†â–†â–†â–…â–„â–…â–„â–…â–†â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–‚â–â–â–ƒâ–â–â–‚â–‚</td></tr><tr><td>training_sequence_accuracy</td><td>â–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ˆâ–â–†â–â–ƒâ–â–†â–â–†â–ƒâ–â–ƒâ–â–†â–ƒâ–†â–†â–†â–â–ƒâ–†â–â–ƒâ–†â–ƒ</td></tr><tr><td>training_token_accuracy</td><td>â–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ˆâ–â–†â–â–ƒâ–â–†â–â–†â–ƒâ–â–ƒâ–â–†â–ƒâ–†â–†â–†â–â–ƒâ–†â–â–ƒâ–†â–ƒ</td></tr><tr><td>validation_loss</td><td>â–„â–â–ƒâ–„â–ƒâ–…â–ƒâ–„â–ƒâ–…â–…â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–…â–ƒâ–„â–„â–…â–ƒâ–„â–ƒâ–…â–ˆâ–ƒâ–…â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–…â–…â–ˆ</td></tr><tr><td>validation_sequence_accuracy</td><td>â–â–…â–†â–ƒâ–ƒâ–ƒâ–†â–…â–ƒâ–…â–…â–ƒâ–†â–ƒâ–â–ˆâ–†â–…â–ƒâ–ƒâ–†â–†â–…â–…â–…â–ˆâ–ƒâ–…â–…â–…â–†â–ƒâ–†â–†â–ƒâ–ƒâ–…â–†â–ƒâ–…</td></tr><tr><td>validation_token_accuracy</td><td>â–â–…â–†â–ƒâ–ƒâ–ƒâ–†â–…â–ƒâ–…â–…â–ƒâ–†â–ƒâ–â–ˆâ–†â–…â–ƒâ–ƒâ–†â–†â–…â–…â–…â–ˆâ–ƒâ–…â–…â–…â–†â–ƒâ–†â–†â–ƒâ–ƒâ–…â–†â–ƒâ–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification/accuracy</td><td>0.55</td></tr><tr><td>classification/auprc</td><td>0.53467</td></tr><tr><td>classification/auroc</td><td>0.56656</td></tr><tr><td>classification/f1.0</td><td>0.60177</td></tr><tr><td>classification/precision</td><td>0.53968</td></tr><tr><td>classification/recall</td><td>0.68</td></tr><tr><td>elapsed_examples</td><td>8004.0</td></tr><tr><td>elapsed_tokens</td><td>4094148.0</td></tr><tr><td>fine_tuned_model</td><td>davinci:ft-academics...</td></tr><tr><td>status</td><td>succeeded</td></tr><tr><td>training_loss</td><td>0.32328</td></tr><tr><td>training_sequence_accuracy</td><td>1.0</td></tr><tr><td>training_token_accuracy</td><td>1.0</td></tr><tr><td>validation_loss</td><td>1.08478</td></tr><tr><td>validation_sequence_accuracy</td><td>0.25</td></tr><tr><td>validation_token_accuracy</td><td>0.25</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">ft-ZdWDUbAnwZ4JDw8fwJRWjV4E</strong>: <a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-ZdWDUbAnwZ4JDw8fwJRWjV4E\" target=\"_blank\">https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-ZdWDUbAnwZ4JDw8fwJRWjV4E</a><br/>Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221202_130454-ft-ZdWDUbAnwZ4JDw8fwJRWjV4E/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Parameter Run\n",
        "\n",
        "prompt_loss_weight=X\n",
        "default_parameters_otherwise."
      ],
      "metadata": {
        "id": "uIfnRkxd_7dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_tag = \"reward_model_classification_final_run\"\n",
        "sweep_parameters = {\n",
        "                    \"prompt_loss_weight\":[0.001], \n",
        "}\n",
        "suffix = \"reward_model_classification\""
      ],
      "metadata": {
        "id": "DkC03bxnAAmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_sets_for_sweep = build_parameter_sets(sweep_parameters)\n",
        "print(\"Number of configs\", len(parameter_sets_for_sweep))\n",
        "for config in parameter_sets_for_sweep:\n",
        "  print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacb3546-1ebc-4394-fe71-8ee5ac573823",
        "id": "7SQ1Wze6AAmR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of configs 1\n",
            "{'prompt_loss_weight': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_classification_dataset_path = \"summarization_finetuning_datasets/reward_model_classification_finetuning_dataset_train_5000.jsonl\"\n",
        "train_classification_dataset_id = upload_dataset_to_openai(train_classification_dataset_path)\n",
        "dev_classification_dataset_path = \"summarization_finetuning_datasets/reward_model_classification_finetuning_dataset_validation_400.jsonl\"\n",
        "development_classification_dataset_id = upload_dataset_to_openai(dev_classification_dataset_path)\n",
        "print(\"Train dataset id {}\".format(train_classification_dataset_id))\n",
        "print(\"Validation dataset id {}\".format(development_classification_dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f978f22c-a6ce-4c0b-bc46-d4db51ed6217",
        "id": "iDXOrvJCAAmS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset id file-9gbvLkFORbT15wiZgFJ0ot9Q\n",
            "Validation dataset id file-06z43lNOgsDKznTMsp3yYwaA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = [], []\n",
        "for parameter_set in parameter_sets_for_sweep: \n",
        "  finetuning_summaries_hp_tuning, finetuning_ids_hp_tuning = initialize_gpt3_finetuning_job(config=parameter_set, train_dataset_id=train_classification_dataset_id, validation_dataset_id=development_classification_dataset_id, finetuning_summaries=finetuning_summaries_hp_tuning, finetuning_ids=finetuning_ids_hp_tuning, positive_class=\" Yes\", suffix=suffix, use_all_hyperparameters=False)\n",
        "print(finetuning_ids_hp_tuning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31cabbcd-b824-4e55-88dc-297c7f78c8f5",
        "id": "Sbkd7I34AAmS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized job ft-rcFTogqGUyM2pPRSpJZXIGR4\n",
            "with config {'prompt_loss_weight': 0.001}\n",
            "\n",
            "\n",
            "\n",
            "['ft-rcFTogqGUyM2pPRSpJZXIGR4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.get -i \"ft-rcFTogqGUyM2pPRSpJZXIGR4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30deed8b-238c-4d76-85b0-7e35b9376e23",
        "id": "Y1UBJAL3AAmS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1669993498,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1669993498,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-rcFTogqGUyM2pPRSpJZXIGR4\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669995096,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune costs $479.93\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1669995096,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune enqueued. Queue number: 10\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": 16,\n",
            "    \"classification_n_classes\": 2,\n",
            "    \"classification_positive_class\": \" Yes\",\n",
            "    \"compute_classification_metrics\": true,\n",
            "    \"learning_rate_multiplier\": 0.1,\n",
            "    \"n_epochs\": 4,\n",
            "    \"prompt_loss_weight\": 0.001\n",
            "  },\n",
            "  \"id\": \"ft-rcFTogqGUyM2pPRSpJZXIGR4\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-rRALD2hkdlmLWNVCKk9PG5Xq\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"pending\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 17248925,\n",
            "      \"created_at\": 1669993493,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-9gbvLkFORbT15wiZgFJ0ot9Q\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1669995096,\n",
            "  \"validation_files\": [\n",
            "    {\n",
            "      \"bytes\": 698807,\n",
            "      \"created_at\": 1669993494,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-06z43lNOgsDKznTMsp3yYwaA\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_ids_hp_tuning = ['ft-rcFTogqGUyM2pPRSpJZXIGR4']\n",
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  print(f\"Monitoring {finetuning_id} ...\")\n",
        "  !openai api fine_tunes.follow -i {finetuning_id}\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79237ed5-ff34-4516-fa40-5de438e0b1f4",
        "id": "4gEWUS1RAAmS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring ft-rcFTogqGUyM2pPRSpJZXIGR4 ...\n",
            "[2022-12-02 15:04:58] Created fine-tune: ft-rcFTogqGUyM2pPRSpJZXIGR4\n",
            "[2022-12-02 15:31:36] Fine-tune costs $479.93\n",
            "[2022-12-02 15:31:36] Fine-tune enqueued. Queue number: 10\n",
            "[2022-12-02 15:38:53] Fine-tune is in the queue. Queue number: 9\n",
            "[2022-12-02 15:38:54] Fine-tune is in the queue. Queue number: 8\n",
            "[2022-12-02 15:39:34] Fine-tune is in the queue. Queue number: 7\n",
            "[2022-12-02 15:41:51] Fine-tune is in the queue. Queue number: 6\n",
            "[2022-12-02 15:42:02] Fine-tune is in the queue. Queue number: 5\n",
            "[2022-12-02 15:46:30] Fine-tune is in the queue. Queue number: 4\n",
            "[2022-12-02 15:52:41] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-02 15:58:10] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-02 16:02:08] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-02 16:11:57] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-02 16:13:35] Fine-tune started\n",
            "[2022-12-02 17:00:57] Fine-tune is in the queue. Queue number: 3\n",
            "[2022-12-02 17:03:25] Fine-tune is in the queue. Queue number: 2\n",
            "[2022-12-02 17:06:24] Fine-tune is in the queue. Queue number: 1\n",
            "[2022-12-02 17:08:08] Fine-tune is in the queue. Queue number: 0\n",
            "[2022-12-02 17:11:56] Fine-tune started\n",
            "[2022-12-02 17:50:43] Completed epoch 1/4\n",
            "[2022-12-02 18:28:29] Completed epoch 2/4\n",
            "[2022-12-02 19:06:04] Completed epoch 3/4\n",
            "[2022-12-02 19:43:40] Completed epoch 4/4\n",
            "[2022-12-02 19:44:54] Uploaded model: davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-19-44-54\n",
            "[2022-12-02 19:44:55] Uploaded result file: file-51tPOKSoBSTGGlvjpsacpw8B\n",
            "[2022-12-02 19:44:55] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-academicsnyuperez:reward-model-classification-2022-12-02-19-44-54 -p <YOUR_PROMPT>\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning_ids_hp_tuning = ['ft-rcFTogqGUyM2pPRSpJZXIGR4']\n",
        "for finetuning_id in finetuning_ids_hp_tuning:\n",
        "  WandbLogger.sync(finetuning_id, project=\"training_language_models_with_langauge_feedback\", entity=\"jerry_crea\", tags=[sweep_tag])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "N3HGY3_EA4tS",
        "outputId": "bc37d1ac-b06f-4edb-b8f6-8aac9ed2a91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221203_080435-ft-rcFTogqGUyM2pPRSpJZXIGR4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback/runs/ft-rcFTogqGUyM2pPRSpJZXIGR4\" target=\"_blank\">ft-rcFTogqGUyM2pPRSpJZXIGR4</a></strong> to <a href=\"https://wandb.ai/jerry_crea/training_language_models_with_langauge_feedback\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
          ]
        }
      ]
    }
  ]
}